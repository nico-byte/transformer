{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to ./.nltk...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "import warnings\n",
    "import yaml\n",
    "\n",
    "import nltk\n",
    "from data import IWSLT2017DataLoader, Multi30kDataLoader\n",
    "from transformer import Seq2SeqTransformer\n",
    "from trainer import Trainer, EarlyStopper\n",
    "from config import SharedConfig, TokenizerConfig, DataLoaderConfig, TransformerConfig, TrainerConfig\n",
    "from translate import Translate\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "nltk.download('wordnet', download_dir='./.venv/share/nltk_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'src_language': 'de', 'tgt_language': 'en', 'src_tokenizer': functools.partial(<function _spacy_tokenize at 0x7f249cfb09a0>, spacy=<spacy.lang.de.German object at 0x7f24b36a69c0>), 'tgt_tokenizer': functools.partial(<function _spacy_tokenize at 0x7f249cfb09a0>, spacy=<spacy.lang.en.English object at 0x7f24b36a6e10>)}\n",
      "{'dataset': 'multi30k', 'batch_size': 32, 'num_workers': 4, 'pin_memory': True, 'drop_last': False, 'shuffle': True}\n",
      "{'token_transform': {'de': functools.partial(<function _spacy_tokenize at 0x7f249cfb09a0>, spacy=<spacy.lang.de.German object at 0x7f24b36a69c0>), 'en': functools.partial(<function _spacy_tokenize at 0x7f249cfb09a0>, spacy=<spacy.lang.en.English object at 0x7f24b36a6e10>)}, 'text_transform': {}, 'vocab_transform': {}, 'dataloaders': [], 'special_symbols': ['<unk>', '<bos>', '<eos>', '<pad>']}\n",
      "Sample from trainset: ('Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.', 'Two young, White males are outside near many bushes.')\n",
      "Sample from valset: ('Ein Inline-Skater in roten Hosen und blauem Hemd, skatet zwischen grünen Kegeln.', 'An inline skater in red pants and blue shirt skates between green cones.')\n",
      "\n",
      "{'de': Vocab(), 'en': Vocab()}\n",
      "{'de': <function BaseDataLoader.sequential_transforms.<locals>.func at 0x7f2458f7b600>, 'en': <function BaseDataLoader.sequential_transforms.<locals>.func at 0x7f244eb18ae0>}\n"
     ]
    }
   ],
   "source": [
    "path_to_config = './configs/multi30k-small.yaml'\n",
    "run_id = 'multi30k-small'\n",
    "device = 'cuda'\n",
    "      \n",
    "with open(path_to_config) as stream:\n",
    "      config = yaml.safe_load(stream)\n",
    "      \n",
    "tkn_conf = TokenizerConfig()\n",
    "print(tkn_conf.model_dump())\n",
    "      \n",
    "tokenizer = {\n",
    "      tkn_conf.src_language: tkn_conf.src_tokenizer,\n",
    "      tkn_conf.tgt_language: tkn_conf.tgt_tokenizer\n",
    "}\n",
    "\n",
    "\n",
    "shared_conf = SharedConfig()\n",
    "dl_conf = DataLoaderConfig(**config['dataloader'])\n",
    "print(shared_conf.model_dump())\n",
    "print(dl_conf.model_dump())\n",
    "\n",
    "if dl_conf.dataset == \"iwslt2017\":\n",
    "      dataloader = IWSLT2017DataLoader(dl_conf, tokenizer, tkn_conf, shared_conf)\n",
    "else:\n",
    "      dataloader = Multi30kDataLoader(dl_conf, tokenizer, tkn_conf, shared_conf)\n",
    "            \n",
    "vocab_transform, text_transform = dataloader.vocab_transform, dataloader.text_transform\n",
    "train_dataloader, test_dataloader, val_dataloader = dataloader.train_dataloader, dataloader.test_dataloader, dataloader.val_dataloader\n",
    "            \n",
    "SRC_VOCAB_SIZE = len(vocab_transform[tkn_conf.src_language].index2word)\n",
    "TGT_VOCAB_SIZE = len(vocab_transform[tkn_conf.tgt_language].index2word)\n",
    "print(SRC_VOCAB_SIZE)\n",
    "print(TGT_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_encoder_layers': 6, 'num_decoder_layers': 6, 'emb_size': 512, 'nhead': 16, 'src_vocab_size': 18652, 'tgt_vocab_size': 10615, 'dim_feedforward': 512, 'dropout': 0.1, 'shared_store': {'token_transform': {'de': functools.partial(<function _spacy_tokenize at 0x7f249cfb09a0>, spacy=<spacy.lang.de.German object at 0x7f24b36a69c0>), 'en': functools.partial(<function _spacy_tokenize at 0x7f249cfb09a0>, spacy=<spacy.lang.en.English object at 0x7f24b36a6e10>)}, 'text_transform': {'de': <function BaseDataLoader.sequential_transforms.<locals>.func at 0x7f2458f7b600>, 'en': <function BaseDataLoader.sequential_transforms.<locals>.func at 0x7f244eb18ae0>}, 'vocab_transform': {'de': Vocab(), 'en': Vocab()}, 'dataloaders': [<torch.utils.data.dataloader.DataLoader object at 0x7f24b0dc1ca0>, <torch.utils.data.dataloader.DataLoader object at 0x7f249d66e510>, <torch.utils.data.dataloader.DataLoader object at 0x7f244ea7b290>], 'special_symbols': ['<unk>', '<bos>', '<eos>', '<pad>']}}\n",
      "{'learning_rate': 0.0001, 'num_epochs': 200, 'batch_size': 32, 'tgt_batch_size': 1024, 'num_cycles': 6, 'stepsize': None, 'device': device(type='cuda')}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #\n",
       "=========================================================================================================\n",
       "Seq2SeqTransformer                                      [1, 32, 10615]            --\n",
       "├─TokenEmbedding: 1-1                                   [1, 32, 512]              --\n",
       "│    └─Embedding: 2-1                                   [1, 32, 512]              9,549,824\n",
       "├─PositionalEncoding: 1-2                               [1, 32, 512]              --\n",
       "│    └─Dropout: 2-2                                     [1, 32, 512]              --\n",
       "├─TokenEmbedding: 1-3                                   [1, 32, 512]              --\n",
       "│    └─Embedding: 2-3                                   [1, 32, 512]              5,434,880\n",
       "├─PositionalEncoding: 1-4                               [1, 32, 512]              --\n",
       "│    └─Dropout: 2-4                                     [1, 32, 512]              --\n",
       "├─Transformer: 1-5                                      [1, 32, 512]              --\n",
       "│    └─TransformerEncoder: 2-5                          [1, 32, 512]              --\n",
       "│    │    └─ModuleList: 3-1                             --                        9,467,904\n",
       "│    │    └─LayerNorm: 3-2                              [1, 32, 512]              1,024\n",
       "│    └─TransformerDecoder: 2-6                          [1, 32, 512]              --\n",
       "│    │    └─ModuleList: 3-3                             --                        15,777,792\n",
       "│    │    └─LayerNorm: 3-4                              [1, 32, 512]              1,024\n",
       "├─Linear: 1-6                                           [1, 32, 10615]            5,445,495\n",
       "=========================================================================================================\n",
       "Total params: 45,677,943\n",
       "Trainable params: 45,677,943\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 26.77\n",
       "=========================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 10.32\n",
       "Params size (MB): 107.07\n",
       "Estimated Total Size (MB): 117.39\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_conf = TransformerConfig(\n",
    "      **config['transformer'],\n",
    "      src_vocab_size=SRC_VOCAB_SIZE,\n",
    "      tgt_vocab_size=TGT_VOCAB_SIZE\n",
    ")\n",
    "print(model_conf.model_dump())\n",
    "\n",
    "transformer = Seq2SeqTransformer(model_conf)\n",
    "translator = Translate(transformer, device, shared_conf.special_symbols)\n",
    "\n",
    "trainer_conf = TrainerConfig(\n",
    "      **config['trainer'],\n",
    "      device=device\n",
    ")\n",
    "print(trainer_conf.model_dump())\n",
    "\n",
    "summary(transformer, [(256, dl_conf.batch_size), (256, dl_conf.batch_size), \n",
    "                      (256, 256), (256, 256), \n",
    "                      (dl_conf.batch_size, 256), (dl_conf.batch_size, 256)], depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: <⚠︎                                       > (!) 0/200 [0%] in 1.2s (0.00/s) \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m early_stopper \u001b[38;5;241m=\u001b[39m EarlyStopper(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.03\u001b[39m)\n\u001b[1;32m      3\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(transformer, early_stopper, trainer_conf, shared_store)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEvaluation: meteor_score  - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mevaluate(tgt_language\u001b[38;5;241m=\u001b[39mtkn_conf\u001b[38;5;241m.\u001b[39mtgt_language)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m TEST_SEQUENCE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEin Mann mit blonden Haar hat ein Haus aus Steinen gebaut .\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/home/Coding/python/transformer/trainer.py:153\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m alive_bar(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer_config\u001b[38;5;241m.\u001b[39mnum_epochs, \n\u001b[1;32m    149\u001b[0m                bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcircles\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m    150\u001b[0m                title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m    151\u001b[0m                title_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m bar:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer_config\u001b[38;5;241m.\u001b[39mnum_epochs):\n\u001b[0;32m--> 153\u001b[0m         train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m avg_training_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    156\u001b[0m         test_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_epoch(epoch, bar)\n",
      "File \u001b[0;32m/home/Coding/python/transformer/trainer.py:75\u001b[0m, in \u001b[0;36mTrainer.train_epoch\u001b[0;34m(self, epoch, bar)\u001b[0m\n\u001b[1;32m     72\u001b[0m tgt_out \u001b[38;5;241m=\u001b[39m tgt[\u001b[38;5;241m1\u001b[39m:, :]\n\u001b[1;32m     74\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(logits\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, logits\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]), tgt_out\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 75\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad_accum \u001b[38;5;129;01mand\u001b[39;00m (batch_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccumulation_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters():\n",
      "File \u001b[0;32m~/.conda/envs/trf/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/trf/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/trf/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "early_stopper = EarlyStopper(patience=3, min_delta=0)\n",
    "\n",
    "trainer = Trainer(transformer, translator, train_dataloader, test_dataloader, val_dataloader, \n",
    "                  vocab_transform, early_stopper, trainer_conf, shared_conf, run_id, device)\n",
    "\n",
    "trainer.train()\n",
    "print(f'\\nEvaluation: meteor_score - {trainer.evaluate(tgt_language=tkn_conf.tgt_language)}')\n",
    "\n",
    "TEST_SEQUENCE = \"Ein Mann mit blonden Haar hat ein Haus aus Steinen gebaut .\"\n",
    "output = translator.translate(TEST_SEQUENCE, src_language=tkn_conf.src_language, \n",
    "                              tgt_language=tkn_conf.tgt_language, text_transform=text_transform, \n",
    "                              vocab_transform=vocab_transform, special_symbols=shared_conf.special_symbols)\n",
    "      \n",
    "print(f'Input: {TEST_SEQUENCE}, Output: {tokenizer.convert_tokens_to_string(output)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
