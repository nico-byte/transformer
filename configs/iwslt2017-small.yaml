dataloader:
  dataset: 'iwslt2017'
  batch_size: 128
  num_workers: 4
  pin_memory: True
  drop_last: False
  shuffle: True
transformer:
  num_encoder_layers: 5
  num_decoder_layers: 5
  emb_size: 1024
  nhead: 32
  dim_feedforward: 2048
  dropout: 0.1
trainer:
  learning_rate: 0.00007
  num_epochs: 30
  tgt_batch_size: 2048
  warmup_steps: 4500